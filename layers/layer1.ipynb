{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   },
   "source": [
    "# Following the paper \"Learning a deep convolutional Networkfor image super-resolution\"\n",
    "\n",
    "The first layer of the network is formally expressed as:\n",
    "\n",
    "$$F_1(\\textbf{Y}) = \\max(0,W_1 * \\textbf{Y} + B_1)$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\textbf{Y}$ is our interpolated (undersampled) image\n",
    "- $\\textbf{X}$ is our ground truth image\n",
    "- $W_1$ is the filter\n",
    "    - of size $c\\times f_1 \\times f_1 \\times n_1$\n",
    "    - $c$ is the number of channels in the input image\n",
    "    - $f_1$ is the spacial size of the filter \n",
    "    - $n_1$ is the number of filters\n",
    "- $B_1$ is the bias\n",
    "\n",
    "- We want to recover from $\\textbf{Y}$ an image $F(\\textbf{Y}) \\approx \\textbf{X}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "c = 0\n",
    "c_out = c\n",
    "f_1 = 0\n",
    "n_1 = 1 # number of convs to apply\n",
    "modules = []\n",
    "\n",
    "conv_layers = [nn.Conv2d(c, c_out, kernel_size=f_1, stride=1, padding=2) for i in range(n_1)]\n",
    "\n",
    "modules = conv_layers.append(nn.ReLU)\n",
    "\n",
    "hidden0 = nn.Sequential(*modules)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}